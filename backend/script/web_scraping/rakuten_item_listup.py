from logging import info
import os
import json
import requests

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
currentDir = os.path.dirname(os.path.abspath(__file__))
resultsDir = os.path.join(currentDir, 'results')

# jsonãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã‚€
with open(os.path.join(currentDir, 'secret.json'), 'r', encoding='utf-8') as f:
    secretData = json.load(f)

ApiUrl = secretData["apiurl"]
ApplicationId = secretData["applicationId"]


# çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
if not os.path.exists(resultsDir):
    os.makedirs(resultsDir, exist_ok=True)


# CSVã«ä¿å­˜ã™ã‚‹é–¢æ•°
def saveToCSV(items, currentPage, csvPath, requirements):

    csvData = []
    print(f"ğŸ“¦ {len(items)}ä»¶ã®å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ (ãƒšãƒ¼ã‚¸ {currentPage}):")

    for index, item in enumerate(items):
        
        info = item.get("Item", item)
        name = info.get("itemName", info.get("productName", "-"))
        catchcopy = info.get("catchcopy", "-")
        availability = info.get("availability", "-")
        price = info.get("itemPrice", info.get("productPrice", "-"))
        url = info.get("itemUrl", info.get("productUrl", "-"))
        shopName = info.get("shopName", "-")
        shopUrl = info.get("shopUrl", "-")

        # if requirements is matched then skip the item to write
        if requirements and "cost" in requirements and "makers" in requirements:
            try:
                min_cost = requirements["cost"][0]["min"]
                max_cost = requirements["cost"][1]["max"]
                makers = requirements["makers"]

                if min_cost < price < max_cost and any(maker in name for maker in makers):
                    print(f"âŒ {name} - Â¥{price} ã¯è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“")
                    continue
            except Exception:
                print("è¦ä»¶ã®ãƒã‚§ãƒƒã‚¯ãŒä¸å®Œå…¨ã§ã™ã€‚ã™ã¹ã¦ã®å•†å“ã‚’ä¿å­˜ã—ã¾ã™ã€‚")

        row = f"{name},{catchcopy},{availability},{price},{url},{shopName},{shopUrl},{currentPage}\n"
        
        if not os.path.exists(csvPath) or os.stat(csvPath).st_size == 0:
            with open(csvPath, 'w', encoding='utf-8') as f:
                f.write(row)
        else:
            with open(csvPath, 'a', encoding='utf-8') as f:
                f.write(row)
        csvData.append(row)
        print(f"{index + 1}. {name} - Â¥{price} - {shopName}")
    print(f"âœ… {currentPage}ãƒšãƒ¼ã‚¸ç›® {len(csvData)}ä»¶ã®å•†å“ã‚’CSVã«ä¿å­˜ã—ã¾ã—ãŸ: {csvPath}")
    return len(csvData)
    

# RapidAPIçµŒç”±ã§æ¥½å¤©å•†å“æ¤œç´¢
def fetchItemsViaRapidAPI(keyword, csvPath, parameters):

    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®åˆæœŸåŒ–
    with open(csvPath, 'w', encoding='utf-8') as f:
        f.write('')

    headers = 'Name,Catchcopy,Availability,Price,URL,Shop,ShopURL,Page\n'
    with open(csvPath, 'w', encoding='utf-8') as f:
        f.write(headers)

    all_items = []
    total_csv_data_num = 0

    # e.g 
    # https://app.rakuten.co.jp/services/api/IchibaItem/Search/20220601?applicationId=[APPLICATION ID]
    # &keyword=%E7%A6%8F%E8%A2%8B
    # &sort=%2BitemPrice

    url = f"{ApiUrl}?applicationId={ApplicationId}"

    try:
        print('ğŸ›ï¸ RapidAPIçµŒç”±ã§æ¥½å¤©å•†å“ã‚’æ¤œç´¢ä¸­...');
        
        for page_num in range(parameters["max_page"]):

            params = {
                "keyword": keyword,
                "format": "json",
                "page": page_num + 1,
                "hits": parameters["number_hits"]
            }
            
            response = requests.get(url, params=params, timeout=30)
            data = response.json()

            first_item = data["Items"][0]["Item"]
            for key, value in first_item.items():
                print(f"{key}: {value}")

            print(f"âœ… APIå‘¼ã³å‡ºã—æˆåŠŸ (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code})")
            
            if data and data.get("products"):
                csv_data_num = saveToCSV(data.get("products"), page_num, csvPath, parameters["requirements"]) # products, currentPage, csvPath, requirements
            
            elif data and data.get("Items"):
                csv_data_num = saveToCSV(data.get("Items"), page_num, csvPath, parameters["requirements"]) # items, currentPage, csvPath, requirements
            else:
                print('âš ï¸ å•†å“ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ')
                print('ãƒ¬ã‚¹ãƒãƒ³ã‚¹:', json.dumps(data, ensure_ascii=False, indent=2))
            all_items.extend(data.get('Items', []))
            total_csv_data_num += csv_data_num

        return all_items, total_csv_data_num
        
    except Exception as error:
        print('âŒ RapidAPIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼:', str(error))
        if (error.response):
            print('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:', error.response.status)
            print('ãƒ¬ã‚¹ãƒãƒ³ã‚¹:', error.response.data)
            raise error


# reactã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚‹ãƒ¡ã‚¤ãƒ³é–¢æ•°
def main(number_hits, page, max_page, keywords):

    parameters = {
        "number_hits": number_hits,
        "page": page,
        "max_page": max_page,
        "keywords": keywords
    }

    results = {}

    for keyword in parameters["keywords"]:
        csvPath = os.path.join(resultsDir, f"rakuten_products_{keyword}.csv")

        
        print(f"ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ \"{keyword}\" ã§å•†å“æ¤œç´¢ã‚’é–‹å§‹...")

        try:
            data, total_csv_data_num = fetchItemsViaRapidAPI(keyword, csvPath, parameters)
        except Exception as error:
            results[keyword] = {
                "status": "error", 
                "message": str(error)
            }

            # affiliateRate       = data["affiliateRate"]
            # affiliateUrl        = data["affiliateUrl"]
            # asurakuArea         = data["asurakuArea"]
            # asurakuClosingTime  = data["asurakuClosingTime"]
            # asurakuFlag         = data["asurakuFlag"]
            # availability        = data["availability"]
            # catchcopy           = data["catchcopy"]
            # creditCardFlag      = data["creditCardFlag"]
            # endTime             = data["endTime"]
            # genreId             = data["genreId"]
            # giftFlag            = data["giftFlag"]
            # imageFlag           = data["imageFlag"]
            # itemCaption         = data["itemCaption"]
            # itemCode            = data["itemCode"]
            # itemName            = data["itemName"]
            # itemPrice           = data["itemPrice"]
            # itemPriceBaseField  = data["itemPriceBaseField"]
            # itemPriceMax1       = data["itemPriceMax1"]
            # itemPriceMax2       = data["itemPriceMax2"]
            # itemPriceMax3       = data["itemPriceMax3"]
            # itemPriceMin1       = data["itemPriceMin1"]
            # itemPriceMin2       = data["itemPriceMin2"]
            # itemPriceMin3       = data["itemPriceMin3"]
            # itemUrl             = data["itemUrl"]
            # mediumImageUrls     = data["mediumImageUrls"]
            # pointRate           = data["pointRate"]
            # pointRateEndTime    = data["pointRateEndTime"]
            # pointRateStartTime  = data["pointRateStartTime"]
            # postageFlag         = data["postageFlag"]
            # reviewAverage       = data["reviewAverage"]
            # reviewCount         = data["reviewCount"]
            # shipOverseasArea    = data["shipOverseasArea"]
            # shipOverseasFlag    = data["shipOverseasFlag"]
            # shopAffiliateUrl    = data["shopAffiliateUrl"]
            # shopCode            = data["shopCode"]
            # shopName            = data["shopName"]
            # shopOfTheYearFlag   = data["shopOfTheYearFlag"]
            # shopUrl             = data["shopUrl"]
            # smallImageUrls      = data["smallImageUrls"]
            # startTime           = data["startTime"]
            # tagIds              = data["tagIds"]
            # taxFlag             = data["taxFlag"]
            results[keyword] = {
                "status": "success",
                "CSV": csvPath,
                "DATA": data,
                "CSV_DATA_NUM": total_csv_data_num
            }

    return results

if __name__ == "__main__":
    # Example parameters

    # "number_hits": 30,
    # "page": 1,
    # "max_page": 3,
    # "keywords": [
    #     "ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—PC", 
    #     "laptop"
    # ],
    # "requirements": {
    #     "cost": [
    #         { "min": 40000 },
    #         { "max": 200000 }
    #     ],
    #     "makers": [
    #         "ASUS",
    #         "Acer",
    #         "HP"
    #     ]
    # }
    main(5, 1, 2, ["ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³"])